{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ebb682d2-0f94-43f9-8971-239a40ab19f5",
   "metadata": {},
   "source": [
    "# ML Flow on Azure ML\n",
    "\n",
    "The ML ops demo notebook shows running ML Flow on a local machine, and the AzureML notebook demonstrates using the Azure ML SDK for experiment tracking. This notebook combines the two, using AzureML to run, but tracking through the ML Flow API with AzureML providing the backend storage. This allows us to make use of the easily scaling  infrastructure of AzureML, while the code is still portable as other backends can easily be swapped in when required.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "preliminary-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06959be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8300679e-340d-4fa3-9c7c-b23dc2ca9935",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e40a4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, concatenate\n",
    "from tensorflow.keras.layers import ZeroPadding1D, Reshape, Input, Dropout, PReLU\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fb927817-9259-4eda-b835-de060914651f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/08/19 12:14:49 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5b55f2dc-9d4e-49b4-9965-5d0a7d25d458",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml\n",
    "import azureml.core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8be64f6-152c-4dc2-bdca-8bc8f292ec90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prd_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c7773b38-e9c6-40eb-afb5-357179a080b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8fc0fc2d-6911-406c-b319-594aa339bfae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'prd_pipeline' from '/mnt/batch/tasks/shared/LS_root/mounts/clusters/prd-ml-pipeline/code/Users/stephen.haddad/precip_rediagnosis/model_pipeline/prd_pipeline.py'>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(prd_pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-investing",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4e372935-d1aa-40dc-8643-1c9a422d8b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train202208_datastore_name = 'precip_rediagnosis_train202208'\n",
    "prd_merged_file_dataset_name = 'prd_merged_csv_files'\n",
    "prd_prefix = 'prd'\n",
    "merged_prefix = prd_prefix + '_merged'\n",
    "csv_file_suffix = 'csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "15ef9973-1466-4a42-b214-646ede49d6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_experiment_name='prd_mlops_test'\n",
    "azure_env_name = 'prd_ml_cluster'\n",
    "cluster_name = 'mlops-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "270e2027-fc87-4b05-8aea-f248982bbeef",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_model_name = 'azml_mlops_202208'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c98d459c-f611-4b85-a5d3-4d2196e9c2ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_all_events_dataset_name = 'prd_merged_all_events_files'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "85382878-1d22-4deb-92b9-58946c4bf878",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_parameter = 'rainfall_rate_composite'\n",
    "profile_features = ['air_temperature', 'relative_humidity']\n",
    "single_lvl_features = ['air_pressure_at_sea_level'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4d4d7c03-3443-46ac-9128-26affe093cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_ws = azureml.core.Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d1145f9a-f0aa-4f19-9589-f5aa85c2606c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(prd_ws.get_mlflow_tracking_uri())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ca91538b-db49-4463-9886-67b4d5f36b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading all event data\n",
      "Downloaded path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/prd/202002_storm_ciara/prd_merged_20200207T1800Z_20200210T1800Z.csv is different from target path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/202002_storm_ciara/prd_merged_20200207T1800Z_20200210T1800Z.csv\n",
      "Downloaded path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/prd/202002_storm_dennis/prd_merged_20200214T1800Z_20200217T1800Z.csv is different from target path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/202002_storm_dennis/prd_merged_20200214T1800Z_20200217T1800Z.csv\n",
      "Downloaded path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/prd/202008_storm_ellen/prd_merged_20200819T0600Z_20200822T1200Z.csv is different from target path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/202008_storm_ellen/prd_merged_20200819T0600Z_20200822T1200Z.csv\n",
      "Downloaded path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/prd/202008_storm_francis/prd_merged_20200824T1800Z_20200826T1200Z.csv is different from target path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/202008_storm_francis/prd_merged_20200824T1800Z_20200826T1200Z.csv\n",
      "Downloaded path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/prd/202010_nswws_amber_oct/prd_merged_20201002T0000Z_20201004T1800Z.csv is different from target path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/202010_nswws_amber_oct/prd_merged_20201002T0000Z_20201004T1800Z.csv\n",
      "Downloaded path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/prd/202012_nswws_amber_dec/prd_merged_20201217T1800Z_20201219T0000Z.csv is different from target path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/202012_nswws_amber_dec/prd_merged_20201217T1800Z_20201219T0000Z.csv\n",
      "Downloaded path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/prd/202102_nswws_amber_feb/prd_merged_20210219T0600Z_20210220T1800Z.csv is different from target path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/202102_nswws_amber_feb/prd_merged_20210219T0600Z_20210220T1800Z.csv\n",
      "Downloaded path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/prd/202110_nswws_amber_oct/prd_merged_20211019T1800Z_20211021T0600Z.csv is different from target path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/202110_nswws_amber_oct/prd_merged_20211019T1800Z_20211021T0600Z.csv\n",
      "Downloaded path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/prd/202112_storm_barra/prd_merged_20211206T1800Z_20211209T0600Z.csv is different from target path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/202112_storm_barra/prd_merged_20211206T1800Z_20211209T0600Z.csv\n",
      "Downloaded path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/prd/2022_storm_eunice_franklin/prd_merged_20220218T1200Z_20220221T1200Z.csv is different from target path: /tmp/tmpzje0kqgx/b02f8326-b2e0-4017-ac7b-be56ac5a4259/2022_storm_eunice_franklin/prd_merged_20220218T1200Z_20220221T1200Z.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/mnt/batch/tasks/shared/LS_root/mounts/clusters/prd-ml-pipeline/code/Users/stephen.haddad/precip_rediagnosis/model_pipeline/prd_pipeline.py:104: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n",
      "  merged_df = pandas.concat([pandas.read_csv(p1) for p1 in prd_path_list])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target has dims: 23\n",
      "dropping zeros\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'rainfall_rate_composite'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/indexes/base.py:2897\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2896\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 2897\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2898\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:107\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:131\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:1607\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:1614\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rainfall_rate_composite'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m input_data \u001b[38;5;241m=\u001b[39m prd_pipeline\u001b[38;5;241m.\u001b[39mload_data(\n\u001b[1;32m      2\u001b[0m     current_ws\u001b[38;5;241m=\u001b[39mprd_ws,\n\u001b[1;32m      3\u001b[0m     dataset_name\u001b[38;5;241m=\u001b[39mprd_all_events_dataset_name\n\u001b[1;32m      4\u001b[0m )\n\u001b[0;32m----> 5\u001b[0m data_splits, data_dims \u001b[38;5;241m=\u001b[39m \u001b[43mprd_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest_fraction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfeature_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mprofile\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprofile_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msingle_level\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43msingle_lvl_features\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_parameter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/prd-ml-pipeline/code/Users/stephen.haddad/precip_rediagnosis/model_pipeline/prd_pipeline.py:240\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[0;34m(input_data, feature_dict, test_fraction)\u001b[0m\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/frame.py:2995\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2993\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2994\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 2995\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2996\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   2997\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/pandas/core/indexes/base.py:2899\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key, method, tolerance)\u001b[0m\n\u001b[1;32m   2897\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine\u001b[38;5;241m.\u001b[39mget_loc(key)\n\u001b[1;32m   2898\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m:\n\u001b[0;32m-> 2899\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_cast_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2900\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer([key], method\u001b[38;5;241m=\u001b[39mmethod, tolerance\u001b[38;5;241m=\u001b[39mtolerance)\n\u001b[1;32m   2901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m indexer\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m indexer\u001b[38;5;241m.\u001b[39msize \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:107\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/index.pyx:131\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:1607\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:1614\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'rainfall_rate_composite'"
     ]
    }
   ],
   "source": [
    "input_data = prd_pipeline.load_data(\n",
    "    current_ws=prd_ws,\n",
    "    dataset_name=prd_all_events_dataset_name\n",
    ")\n",
    "data_splits, data_dims = prd_pipeline.preprocess_data(\n",
    "    input_data=input_data,\n",
    "    test_fraction=0.2,\n",
    "    feature_dict={'profile': profile_features, 'single_level': single_lvl_features,'target': target_parameter,},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7aa31b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "nprof_features = data_dims['nprof_features'] \n",
    "nheights = data_dims['nheights']\n",
    "nsinglvl_features = data_dims['nsinglvl_features']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7def4473-cb5d-401a-9d6b-671682dbddae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp1 = mlflow.create_experiment('prd_exp_azml_mlflow')\n",
    "exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8b3a87b-bdcd-49df-84c7-f37d8aa78004",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = mlflow.get_experiment(exp1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27fd2cd-ecda-4bee-82e3-13a6b876e3bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7243f14-bdd5-4348-ad0e-bf8729197580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir = 'log/fit/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a2ab34-98b2-428a-ae55-4e04fda66df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorflow_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# run tensorboard --logdir LOGDIRPATH from command line to launch "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0669dad0-af4a-496e-83e4-280797bc2fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0343a-b343-4fc3-8cf9-17678d970b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(experiment_id=exp1.experiment_id) as current_run:\n",
    "    model = prd_pipeline.build_model(nprof_features, nheights, nsinglvl_features)\n",
    "    model.summary()\n",
    "    optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)\n",
    "    model.compile(loss='mean_absolute_error', optimizer=optimizer)\n",
    "\n",
    "    history = model.fit(data_splits['X_train'], data_splits['y_train'], epochs=50, batch_size=128, validation_data=(data_splits['X_val'], data_splits['y_val']), verbose=True, callbacks=[tensorflow_callback])\n",
    "\n",
    "    y_pred = model.predict(data_splits['X_val'])\n",
    "    error = mean_absolute_error(data_splits['y_val'], y_pred)\n",
    "    print(f'MAE: {error:.3f}')\n",
    "    rsqrd = r2_score(data_splits['y_val'], y_pred)\n",
    "    print(f'R-squared score: {rsqrd:.3f}')\n",
    "    \n",
    "    mlflow.log_metric('MAE', error)\n",
    "    mlflow.log_metric('R-squared', rsqrd)\n",
    "    \n",
    "    fig1 = plt.figure(figsize=(10, 8))\n",
    "    ax1 = fig1.add_subplot(1,1,1)\n",
    "    ax1.scatter(data_splits['y_val'], y_pred, s=200, c='darkblue')\n",
    "    ax1.plot([0, 300], [0, 300], ls=\"--\", c=\".3\")\n",
    "    ax1.set_xlabel('Actual 3hr precip accumulation value')\n",
    "    ax1.set_ylabel('Predicted 3hr precip_accumulation value')\n",
    "#     with tempfile.TemporaryDirectory() as td1:\n",
    "        \n",
    "#         fig1.savefig(plot_out_path, bbox_inches='tight')\n",
    "    mlflow.log_figure(fig1,  'actual_predicted_precip_3hr.png')                   \n",
    "    # mlflow.log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e739e218-21cf-4ae4-b357-5c226177002f",
   "metadata": {},
   "source": [
    "If we look at the experiment in AzureML GUI, we see that all the model parameters have been automatically logged, and the model has been saved by ML Flow ready for use in inference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0fa07b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fe371a",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_hist_df = pd.DataFrame(history.history)\n",
    "training_hist_df['epoch'] = history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ec093",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.plot(training_hist_df.epoch, training_hist_df.loss, label='training')\n",
    "plt.plot(training_hist_df.epoch, training_hist_df.val_loss, c='g', label='validation')\n",
    "plt.legend()\n",
    "plt.ylabel('MAE [mm of precipitation]')\n",
    "plt.xlabel('epochs')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9560e11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "plt.hist(data_splits['y_val'], alpha=0.5, bins=40, label='Actual')\n",
    "plt.hist(y_pred, alpha=0.5, bins=40, label='Predicted')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197da54b-4b3d-45b0-8ba7-d91ca6839419",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
