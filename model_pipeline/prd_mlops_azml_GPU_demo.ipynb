{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c9842a2-db42-4722-b3e5-43a7ee2040c3",
   "metadata": {},
   "source": [
    "# Training on GPU cluster\n",
    "One of the advantages of running a cluster, is that you can have relatively small instance running for the notebook server and then send of the training task to a separate compute cluster, which can be running powerful (and expensive) GPUs, which spin up to run the training script and then spin down."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70cc5013-7b6d-44f5-a7dc-0a1f3504b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "preliminary-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pathlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "06959be2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6174c25d-ba3c-4ac7-bcca-a3d6f107aeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prd_pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d725a1c-81b0-4aee-8153-1adc1f398ea4",
   "metadata": {},
   "source": [
    "## set up azure experiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3aff8274-8f96-45d5-92ba-49b2b4569fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore, Dataset, Environment\n",
    "from azureml.core import Experiment, ComputeTarget, ScriptRunConfig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c4b67b3e-6f9a-4fc5-b555-481a45ccfd28",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35b08e0c-51b2-4c63-9716-64cbb64f9150",
   "metadata": {},
   "outputs": [],
   "source": [
    "azure_dataset_name ='sd3'\n",
    "azure_experiment_name='prd_mlops_test'\n",
    "azure_env_name = 'prd_ml_cluster'\n",
    "cluster_name = 'mlops-gpu-test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb2d0171-1034-4f27-bc3b-d60dd393d943",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_model_name = 'azml_cluster_demo_20220414'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d9c6b52c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_parameter = 'rainfall_rate_composite'\n",
    "profile_features = ['air_temperature', 'relative_humidity']\n",
    "single_lvl_features = ['air_pressure_at_sea_level'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db8803a5-41f8-46a7-afcc-5e83b8bcec52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Name</th><th>Workspace</th><th>Report Page</th><th>Docs Page</th></tr><tr><td>prd_mlops_test</td><td>precip_rediagnosis</td><td><a href=\"https://ml.azure.com/experiments/id/9e2e4de2-7fc3-4217-a9ee-43723f8330ae?wsid=/subscriptions/07efdc52-cd27-48ed-9443-3aad2b6b777b/resourcegroups/precip_rediagnosis/workspaces/precip_rediagnosis&amp;tid=14fec308-b428-4380-b914-c1940f3210f1\" target=\"_blank\" rel=\"noopener\">Link to Azure Machine Learning studio</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.experiment.Experiment?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Experiment(Name: prd_mlops_test,\n",
       "Workspace: precip_rediagnosis)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd_exp = Experiment(workspace=prd_ws, name=azure_experiment_name)\n",
    "prd_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53da16db-dade-4d96-ac38-a6befff7a589",
   "metadata": {},
   "source": [
    "Get the AzML environment (basically a conda environment) from the workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "16a304bb-23d4-40e3-a0f6-9628efe621dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "    \"databricks\": {\n",
       "        \"eggLibraries\": [],\n",
       "        \"jarLibraries\": [],\n",
       "        \"mavenLibraries\": [],\n",
       "        \"pypiLibraries\": [],\n",
       "        \"rcranLibraries\": []\n",
       "    },\n",
       "    \"docker\": {\n",
       "        \"arguments\": [],\n",
       "        \"baseDockerfile\": null,\n",
       "        \"baseImage\": \"azureml/openmpi3.1.2-cuda10.2-cudnn8-ubuntu18.04\",\n",
       "        \"baseImageRegistry\": {\n",
       "            \"address\": \"mcr.microsoft.com\",\n",
       "            \"password\": null,\n",
       "            \"registryIdentity\": null,\n",
       "            \"username\": null\n",
       "        },\n",
       "        \"enabled\": false,\n",
       "        \"platform\": {\n",
       "            \"architecture\": \"amd64\",\n",
       "            \"os\": \"Linux\"\n",
       "        },\n",
       "        \"sharedVolumes\": true,\n",
       "        \"shmSize\": null\n",
       "    },\n",
       "    \"environmentVariables\": {},\n",
       "    \"inferencingStackVersion\": null,\n",
       "    \"name\": \"prd_ml_cluster\",\n",
       "    \"python\": {\n",
       "        \"baseCondaEnvironment\": null,\n",
       "        \"condaDependencies\": {\n",
       "            \"channels\": [\n",
       "                \"conda-forge\"\n",
       "            ],\n",
       "            \"dependencies\": [\n",
       "                \"python=3.8\",\n",
       "                \"pandas\",\n",
       "                \"scikit-learn\",\n",
       "                \"tensorflow\",\n",
       "                \"pip\",\n",
       "                {\n",
       "                    \"pip\": [\n",
       "                        \"azureml-defaults\"\n",
       "                    ]\n",
       "                }\n",
       "            ],\n",
       "            \"name\": \"azureml_2eac082847a1e59b172ba0901837ac8e\"\n",
       "        },\n",
       "        \"condaDependenciesFile\": null,\n",
       "        \"interpreterPath\": null,\n",
       "        \"userManagedDependencies\": false\n",
       "    },\n",
       "    \"r\": null,\n",
       "    \"spark\": {\n",
       "        \"packages\": [],\n",
       "        \"precachePackages\": true,\n",
       "        \"repositories\": []\n",
       "    },\n",
       "    \"version\": \"3\"\n",
       "}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prd_env = Environment.get(workspace=prd_ws, name=azure_env_name)\n",
    "prd_env"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-investing",
   "metadata": {},
   "source": [
    "### Load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ee5da7-5829-4618-af04-17c9cf53473d",
   "metadata": {},
   "source": [
    "load the data from the script so we'renot duplicating code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "74635d41-c804-4e3c-93e6-c7141e3dbf17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib \n",
    "# importlib.reload(prd_cluster_train_demo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "17ece588-dfe2-4e31-a2c7-e30a66a90039",
   "metadata": {},
   "outputs": [
    {
     "ename": "UserErrorException",
     "evalue": "UserErrorException:\n\tMessage: Cannot find dataset registered with name \"sd3\" (version: None) in the workspace.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Cannot find dataset registered with name \\\"sd3\\\" (version: None) in the workspace.\"\n    }\n}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUserErrorException\u001b[0m                        Traceback (most recent call last)",
      "Input \u001b[0;32mIn [13]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m input_data \u001b[38;5;241m=\u001b[39m \u001b[43mprd_pipeline\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprd_ws\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataset_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mazure_dataset_name\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m data_splits, data_dims \u001b[38;5;241m=\u001b[39m prd_pipeline\u001b[38;5;241m.\u001b[39mpreprocess_data(\n\u001b[1;32m      6\u001b[0m     input_data,\n\u001b[1;32m      7\u001b[0m     feature_dict\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprofile\u001b[39m\u001b[38;5;124m'\u001b[39m: profile_features, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msingle_level\u001b[39m\u001b[38;5;124m'\u001b[39m: single_lvl_features,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtarget\u001b[39m\u001b[38;5;124m'\u001b[39m: target_parameter,},\n\u001b[1;32m      8\u001b[0m )\n",
      "File \u001b[0;32m/mnt/batch/tasks/shared/LS_root/mounts/clusters/prd-ml-pipeline/code/Users/stephen.haddad/precip_rediagnosis/model_pipeline/prd_pipeline.py:101\u001b[0m, in \u001b[0;36mload_data\u001b[0;34m(current_ws, dataset_name)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_data\u001b[39m(current_ws, dataset_name):\n\u001b[1;32m     98\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     99\u001b[0m \u001b[38;5;124;03m    This function loads data from AzureML storage and returns it as a pandas dataframe \u001b[39;00m\n\u001b[1;32m    100\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 101\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mazureml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_ws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdataset_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mmount() \u001b[38;5;28;01mas\u001b[39;00m ds_mount:\n\u001b[1;32m    104\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mloading all event data\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/_loggerfactory.py:132\u001b[0m, in \u001b[0;36mtrack.<locals>.monitor.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _LoggerFactory\u001b[38;5;241m.\u001b[39mtrack_activity(logger, func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, activity_type, custom_dimensions) \u001b[38;5;28;01mas\u001b[39;00m al:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    134\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(al, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactivity_info\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(e, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124merror_code\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/abstract_dataset.py:89\u001b[0m, in \u001b[0;36mAbstractDataset.get_by_name\u001b[0;34m(workspace, name, version)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;129m@staticmethod\u001b[39m\n\u001b[1;32m     76\u001b[0m \u001b[38;5;129m@track\u001b[39m(_get_logger, activity_type\u001b[38;5;241m=\u001b[39m_PUBLIC_API)\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_by_name\u001b[39m(workspace, name, version\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlatest\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;124;03m\"\"\"Get a registered Dataset from workspace by its registration name.\u001b[39;00m\n\u001b[1;32m     79\u001b[0m \n\u001b[1;32m     80\u001b[0m \u001b[38;5;124;03m    :param workspace: The existing AzureML workspace in which the Dataset was registered.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;124;03m    :rtype: typing.Union[azureml.data.TabularDataset, azureml.data.FileDataset]\u001b[39;00m\n\u001b[1;32m     88\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mAbstractDataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mworkspace\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mversion\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     AbstractDataset\u001b[38;5;241m.\u001b[39m_track_lineage([dataset])\n\u001b[1;32m     91\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m dataset\n",
      "File \u001b[0;32m/anaconda/envs/azureml_py38/lib/python3.8/site-packages/azureml/data/abstract_dataset.py:642\u001b[0m, in \u001b[0;36mAbstractDataset._get_by_name\u001b[0;34m(workspace, name, version)\u001b[0m\n\u001b[1;32m    640\u001b[0m success, result \u001b[38;5;241m=\u001b[39m _make_request(request, handle_error)\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m success:\n\u001b[0;32m--> 642\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m result\n\u001b[1;32m    643\u001b[0m dataset \u001b[38;5;241m=\u001b[39m _dto_to_dataset(workspace, result)\n\u001b[1;32m    644\u001b[0m warn_deprecated_blocks(dataset)\n",
      "\u001b[0;31mUserErrorException\u001b[0m: UserErrorException:\n\tMessage: Cannot find dataset registered with name \"sd3\" (version: None) in the workspace.\n\tInnerException None\n\tErrorResponse \n{\n    \"error\": {\n        \"code\": \"UserError\",\n        \"message\": \"Cannot find dataset registered with name \\\"sd3\\\" (version: None) in the workspace.\"\n    }\n}"
     ]
    }
   ],
   "source": [
    "input_data = prd_pipeline.load_data(\n",
    "    prd_ws,\n",
    "    dataset_name=azure_dataset_name\n",
    ")\n",
    "data_splits, data_dims = prd_pipeline.preprocess_data(\n",
    "    input_data,\n",
    "    feature_dict={'profile': profile_features, 'single_level': single_lvl_features,'target': target_parameter,},\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6617411-75b6-440b-bf21-eed2570e71d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# these are example calls to the code for easier debugging than running on a separate cluster\n",
    "# model = prd_cluster_train_demo.build_model(**data_dims)\n",
    "# model = prd_cluster_train_demo.train_model(model, data_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7243f14-bdd5-4348-ad0e-bf8729197580",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "log_dir = 'log/fit/' + datetime.datetime.now().strftime('%Y%m%d-%H%M%S')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6879705d-02a5-457a-81dd-a2efcc3a0d3c",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Execute our training run on a cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee033e3d-f70c-4833-827e-c47272b8327f",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_demo_compute_target = ComputeTarget(workspace=prd_ws, name=cluster_name)\n",
    "prd_demo_compute_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6581fbf3-ec63-4ddb-9346-c1db7f6ff527",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_demo_args = ['--dataset-name', azure_dataset_name,\n",
    "                 '--target-parameter', target_parameter,\n",
    "                 '--model-name', prd_model_name,\n",
    "                ]\n",
    "\n",
    "prd_demo_args += ['--profile-features']\n",
    "prd_demo_args += profile_features\n",
    "prd_demo_args += ['--single-level_features']\n",
    "prd_demo_args += single_lvl_features\n",
    "\n",
    "prd_demo_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a552930a-a4d3-477c-9486-0071247cf723",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_run_src = ScriptRunConfig(source_directory=os.getcwd(),\n",
    "                      script='prd_cluster_train_demo.py',\n",
    "                      arguments=prd_demo_args,\n",
    "                      compute_target=prd_demo_compute_target,\n",
    "                      environment=prd_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f24060-af81-4ab6-b1cd-37e92997c493",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_run = prd_exp.submit(prd_run_src)\n",
    "prd_run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f0fa07b",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluation\n",
    "\n",
    "We now get the trained model to do some evaluatiion and create some plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9d9288-263b-4b1c-9d6d-0b4bd74f27e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ed52b6-7728-4ed2-b796-48053a5e78b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165e4993-96e6-4975-9024-d69c33bb84ac",
   "metadata": {},
   "source": [
    "We download the model file into a temproary directory (so as not to pollute the local workspace) and load into memory to do inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "818a6d03-9f0d-4a40-b0e5-4f95306b4c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "with tempfile.TemporaryDirectory() as td1:\n",
    "    td_path = pathlib.Path(td1)\n",
    "    prd_run.download_files(prefix=prd_model_name, output_directory=td1)\n",
    "    model_path = td_path / prd_model_name\n",
    "    list(model_path.iterdir())\n",
    "    trained_model = tensorflow.keras.models.load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a7f14c-dece-475c-b321-377be47cab0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26af6141-846e-40ef-90ae-8607feeb0b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c68e7789-4683-4caf-a826-17b4a9c47fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = trained_model.predict(data_splits['X_test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7e7dd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = plt.figure(figsize=(10, 8))\n",
    "ax1 = fig1.add_subplot(1,1,1)\n",
    "ax1.scatter(data_splits['y_test'], y_pred, s=200, c='darkblue')\n",
    "ax1.plot([0, 300], [0, 300], ls=\"--\", c=\".3\")\n",
    "ax1.set_xlabel('Actual 3hr precip accumulation value')\n",
    "ax1.set_ylabel('Predicted 3hr precip_accumulation value')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43385cc4-b515-4745-8e9c-2cfcc8624483",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_run.log_image(name='actual_vs_pred', plot=fig1, description='predicted vs actual 3hr accumulations of rainfall')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6a95931-bf51-479e-b9bc-c29fb11059a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_run.complete()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ebee981-e220-4328-a9a9-cfab5ae10ea6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
