{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cc68a0a-ada5-4272-8bb5-7cd0df0059a8",
   "metadata": {},
   "source": [
    "# Machine learning pipeline for modelling fraction of precipitation in different intensity bands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d33dee-b384-4882-af23-5b2c3012b7a7",
   "metadata": {},
   "source": [
    "This notebook is designed to be run in AzureML "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e7f0b3-ffcd-4311-bed3-b5e39d8c89aa",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Import relevant libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ccd2586-7952-4b04-9e66-354340354a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import os\n",
    "import datetime\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "preliminary-idaho",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8300679e-340d-4fa3-9c7c-b23dc2ca9935",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e40a4d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv1D, concatenate\n",
    "from tensorflow.keras.layers import ZeroPadding1D, Reshape, Input, Dropout, PReLU\n",
    "from tensorflow.keras.models import Sequential, Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a22aa912-97be-4bf2-8405-8cda52a88c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import prd_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9ecb54e1-dbc7-46c3-a353-3d6780dfac2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/mnt/batch/tasks/shared/LS_root/mounts/clusters/prd-ml-fractions/code/Users/hannah.brown/precip_rediagnosis')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pathlib.Path.cwd().parent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa75fff-4107-4e56-9347-7472507e473c",
   "metadata": {},
   "source": [
    "Set up MLops for experiment tracking in AzureML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6af55860-af60-492e-9826-af22e021a9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/10/24 15:43:37 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "mlflow.tensorflow.autolog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8ab95044-ea33-451d-8232-dcf480236be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace, Datastore, Dataset\n",
    "from azureml.core import Experiment\n",
    "\n",
    "prd_ws = Workspace.from_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7ff93427-0cdf-43b3-bea1-6bce3a0e1162",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(prd_ws.get_mlflow_tracking_uri())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wireless-investing",
   "metadata": {},
   "source": [
    "### Load and preprocess data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6ec0d5cc-df5c-4a04-930a-49bef5108e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_prefix = 'prd'\n",
    "merged_prefix = prd_prefix + '_merged'\n",
    "csv_file_suffix = 'csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3af345ac-2b1f-4592-829b-d874ca08d521",
   "metadata": {},
   "outputs": [],
   "source": [
    "bands = {\n",
    "    '0.0':[0, 0.01],\n",
    "    '0.25':[0.01, 0.5], \n",
    "    '2.5': [0.5, 4], \n",
    "    '7.0':[4, 10], \n",
    "    '10.0':[10,220]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "709714c6-77ba-4588-a249-958c7a6f375e",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_band_template = '{source}_fraction_in_band_instant_{band_centre}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "41b14934-bf6a-4f50-91bb-fba6a48624fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_parameter = [intensity_band_template.format(source='radar', band_centre=threshold) for threshold in bands.keys()]\n",
    "nwp_comparison = [intensity_band_template.format(source='mogrepsg', band_centre=threshold) for threshold in bands.keys()]\n",
    "\n",
    "profile_features = ['air_temperature', 'relative_humidity', 'wind_speed', 'wind_from_direction', 'cloud_volume_fraction'] #'air_pressure',\n",
    "single_lvl_features = []#'thickness_of_rainfall_amount', 'surface_altitude', 'air_pressure_at_sea_level', 'cloud_area_fraction'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "190ad81c-b092-46fa-8a5b-a362d37754e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict = {\n",
    "    'profile': profile_features,\n",
    "    'single_level': single_lvl_features,\n",
    "    'target': target_parameter,\n",
    "    'nwp': nwp_comparison, \n",
    "    'metadata': ['time', 'realization', 'latitude', 'longitude']\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "12c25415-d751-42b9-875c-902050c874af",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_all = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8c6d5276-fd1f-4a6f-9022-11d22e03fe14",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_all:\n",
    "    prd_azml_dataset_name = 'prd_merged_all_events_files'\n",
    "else:\n",
    "    prd_azml_dataset_name = 'prd_merged_202110_nswws_amber_oct_files'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9e17ae17-dffc-426e-9ff8-807128d6ea10",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_azml_dataset = azureml.core.Dataset.get_by_name(prd_ws, name=prd_azml_dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1f3eadc3-5329-4af9-927f-6e62a23483df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not mounting as a volume: ArgumentError(InvalidArgument { argument: \"arguments.path\", expected: \"Glob patterns inside the path are not supported by the volume mount.Path must be a direct path to the file or folder, or end with '/**' or '/**/*' to match the entire content of the volume.\", actual: \"REDACTED\" }). \n",
      "Falling back to dataflow mount.\n",
      "loading all data\n"
     ]
    }
   ],
   "source": [
    "with prd_azml_dataset.mount() as prd_mount:\n",
    "    print('loading all data')\n",
    "    prd_path_list = [p1 for p1 in pathlib.Path(prd_mount.mount_point).rglob('*csv') ]\n",
    "    merged_df = pd.concat([pd.read_csv(p1) for p1 in prd_path_list])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6185b2e-5240-4bf4-96b6-f780294d812a",
   "metadata": {},
   "source": [
    "### Calculate NWP probabilities of falling in each intensity bands - <i> to be moved into data prep </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "30de40c6-6f52-46e5-8a02-95450f4fdc24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_nwp_probabilities(data, lower_bound, upper_bound):\n",
    "    return ((data>=lower_bound) & (data<upper_bound)).sum()/data.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c31cbc92-f80c-4c38-84e4-2f54ef074ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%timeit\n",
    "nwp_fractions = [\n",
    "    merged_df.groupby(['latitude', 'longitude', 'time'])[['rainfall_rate']].apply(\n",
    "        lambda x: calc_nwp_probabilities(x, lower_bound, upper_bound)).rename(columns={'rainfall_rate':intensity_band_template.format(source='mogrepsg', band_centre=intensity_band)})\n",
    "    for intensity_band, [lower_bound, upper_bound] in bands.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "32ebd8c3-5559-4e31-bd5b-df343fb46a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "nwp_prob_df = pd.concat(nwp_fractions, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bc4bbe9a-9738-48e4-90df-57696a6656e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(merged_df, nwp_prob_df, left_on=['latitude', 'longitude', 'time'], right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8986cf58-597e-420f-8d08-ab0f6d849f6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>realization</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>forecast_period</th>\n",
       "      <th>forecast_reference_time</th>\n",
       "      <th>time</th>\n",
       "      <th>cloud_area_fraction</th>\n",
       "      <th>surface_altitude</th>\n",
       "      <th>air_pressure_at_sea_level</th>\n",
       "      <th>rainfall_rate</th>\n",
       "      <th>...</th>\n",
       "      <th>radar_fraction_in_band_instant_0.0</th>\n",
       "      <th>radar_fraction_in_band_instant_0.25</th>\n",
       "      <th>radar_fraction_in_band_instant_2.5</th>\n",
       "      <th>radar_fraction_in_band_instant_7.0</th>\n",
       "      <th>radar_fraction_in_band_instant_10.0</th>\n",
       "      <th>mogrepsg_fraction_in_band_instant_0.0</th>\n",
       "      <th>mogrepsg_fraction_in_band_instant_0.25</th>\n",
       "      <th>mogrepsg_fraction_in_band_instant_2.5</th>\n",
       "      <th>mogrepsg_fraction_in_band_instant_7.0</th>\n",
       "      <th>mogrepsg_fraction_in_band_instant_10.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>49.40625</td>\n",
       "      <td>-5.484375</td>\n",
       "      <td>0 days 06:00:00</td>\n",
       "      <td>2020-02-07 12:00:00</td>\n",
       "      <td>2020-02-07 18:00:00</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101050.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463529</td>\n",
       "      <td>0.515294</td>\n",
       "      <td>0.025882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>49.40625</td>\n",
       "      <td>-5.484375</td>\n",
       "      <td>0 days 06:00:00</td>\n",
       "      <td>2020-02-07 12:00:00</td>\n",
       "      <td>2020-02-07 18:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101036.0</td>\n",
       "      <td>0.536442</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463529</td>\n",
       "      <td>0.515294</td>\n",
       "      <td>0.025882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>49.40625</td>\n",
       "      <td>-5.484375</td>\n",
       "      <td>0 days 06:00:00</td>\n",
       "      <td>2020-02-07 12:00:00</td>\n",
       "      <td>2020-02-07 18:00:00</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101104.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463529</td>\n",
       "      <td>0.515294</td>\n",
       "      <td>0.025882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>49.40625</td>\n",
       "      <td>-5.484375</td>\n",
       "      <td>0 days 06:00:00</td>\n",
       "      <td>2020-02-07 12:00:00</td>\n",
       "      <td>2020-02-07 18:00:00</td>\n",
       "      <td>0.843750</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101005.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463529</td>\n",
       "      <td>0.515294</td>\n",
       "      <td>0.025882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>49.40625</td>\n",
       "      <td>-5.484375</td>\n",
       "      <td>0 days 06:00:00</td>\n",
       "      <td>2020-02-07 12:00:00</td>\n",
       "      <td>2020-02-07 18:00:00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>101038.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.463529</td>\n",
       "      <td>0.515294</td>\n",
       "      <td>0.025882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows 칑 232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   realization  latitude  longitude  forecast_period forecast_reference_time  \\\n",
       "0            0  49.40625  -5.484375  0 days 06:00:00     2020-02-07 12:00:00   \n",
       "1            1  49.40625  -5.484375  0 days 06:00:00     2020-02-07 12:00:00   \n",
       "2            2  49.40625  -5.484375  0 days 06:00:00     2020-02-07 12:00:00   \n",
       "3            3  49.40625  -5.484375  0 days 06:00:00     2020-02-07 12:00:00   \n",
       "4            4  49.40625  -5.484375  0 days 06:00:00     2020-02-07 12:00:00   \n",
       "\n",
       "                  time  cloud_area_fraction  surface_altitude  \\\n",
       "0  2020-02-07 18:00:00             0.984375               0.0   \n",
       "1  2020-02-07 18:00:00             1.000000               0.0   \n",
       "2  2020-02-07 18:00:00             0.984375               0.0   \n",
       "3  2020-02-07 18:00:00             0.843750               0.0   \n",
       "4  2020-02-07 18:00:00             1.000000               0.0   \n",
       "\n",
       "   air_pressure_at_sea_level  rainfall_rate  ...  \\\n",
       "0                   101050.0       0.000000  ...   \n",
       "1                   101036.0       0.536442  ...   \n",
       "2                   101104.0       0.000000  ...   \n",
       "3                   101005.0       0.000000  ...   \n",
       "4                   101038.0       0.000000  ...   \n",
       "\n",
       "   radar_fraction_in_band_instant_0.0  radar_fraction_in_band_instant_0.25  \\\n",
       "0                            0.463529                             0.515294   \n",
       "1                            0.463529                             0.515294   \n",
       "2                            0.463529                             0.515294   \n",
       "3                            0.463529                             0.515294   \n",
       "4                            0.463529                             0.515294   \n",
       "\n",
       "   radar_fraction_in_band_instant_2.5  radar_fraction_in_band_instant_7.0  \\\n",
       "0                            0.025882                                 0.0   \n",
       "1                            0.025882                                 0.0   \n",
       "2                            0.025882                                 0.0   \n",
       "3                            0.025882                                 0.0   \n",
       "4                            0.025882                                 0.0   \n",
       "\n",
       "   radar_fraction_in_band_instant_10.0  mogrepsg_fraction_in_band_instant_0.0  \\\n",
       "0                                  0.0                               0.666667   \n",
       "1                                  0.0                               0.666667   \n",
       "2                                  0.0                               0.666667   \n",
       "3                                  0.0                               0.666667   \n",
       "4                                  0.0                               0.666667   \n",
       "\n",
       "   mogrepsg_fraction_in_band_instant_0.25  \\\n",
       "0                                0.222222   \n",
       "1                                0.222222   \n",
       "2                                0.222222   \n",
       "3                                0.222222   \n",
       "4                                0.222222   \n",
       "\n",
       "   mogrepsg_fraction_in_band_instant_2.5  \\\n",
       "0                               0.111111   \n",
       "1                               0.111111   \n",
       "2                               0.111111   \n",
       "3                               0.111111   \n",
       "4                               0.111111   \n",
       "\n",
       "   mogrepsg_fraction_in_band_instant_7.0  \\\n",
       "0                                    0.0   \n",
       "1                                    0.0   \n",
       "2                                    0.0   \n",
       "3                                    0.0   \n",
       "4                                    0.0   \n",
       "\n",
       "   mogrepsg_fraction_in_band_instant_10.0  \n",
       "0                                     0.0  \n",
       "1                                     0.0  \n",
       "2                                     0.0  \n",
       "3                                     0.0  \n",
       "4                                     0.0  \n",
       "\n",
       "[5 rows x 232 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d4e38d-a99d-4a49-b43c-d690b63e04c7",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Calculate u and v wind fields and add column to dataset <i>- to be moved into data prep </i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7eb0273b-5f7d-4d6b-b6d4-906b0cebeaf5",
   "metadata": {},
   "source": [
    "Adding columns with u and v wind fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7587216c-5038-4b03-9c92-f60b41511764",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import math\n",
    "\n",
    "# wdir_columns = prd_pipeline.get_profile_columns(['wind_from_direction'], merged_df.columns)\n",
    "# ws_columns = prd_pipeline.get_profile_columns(['wind_speed'], merged_df.columns)\n",
    "\n",
    "# for (wdir, ws) in zip(wdir_columns, ws_columns):\n",
    "#     height_level = wdir.split('_')[-1]\n",
    "#     print(height_level)\n",
    "#     merged_df[f'u_wind_{height_level}'] = merged_df[f'wind_from_direction_{height_level}'].apply(\n",
    "#         lambda x: math.sin(math.radians(270 - x))) * merged_df[f'wind_speed_{height_level}']\n",
    "#     merged_df[f'v_wind_{height_level}'] = merged_df[f'wind_from_direction_{height_level}'].apply(\n",
    "#         lambda x: math.cos(math.radians(270 - x))) * merged_df[f'wind_speed_{height_level}']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2569ab0-6fda-4334-9d88-acb7966aae20",
   "metadata": {},
   "source": [
    "To check the u and v wind conversion, we convert back from u and v wind fields to wind speed and direction and compare this to wind speed and direction in the dataset. This test currently fails as there are a few data points with wind speeds of zero. May be worth some investigation into whether these zero are spurious or not, but perhaps easiest at this stage to filter out zero values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0678cb1d-f405-48ca-81a3-c5ffedd4e152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # test for u and v wind conversion\n",
    "# for (wdir, ws) in zip(wdir_columns, ws_columns):\n",
    "#     height_level = wdir.split('_')[-1]\n",
    "#     print(height_level)\n",
    "#     print(merged_df[(merged_df[f'wind_from_direction_{height_level}'] != np.round(np.rad2deg(np.arctan2(merged_df[f'v_wind_{height_level}'], merged_df[f'u_wind_{height_level}'])) + 180, 4))][[f'wind_from_direction_{height_level}', f'wind_speed_{height_level}']])\n",
    "#     merged_df = merged_df[merged_df[ws] != 0]\n",
    "    \n",
    "#     assert (merged_df[f'wind_speed_{height_level}'] == np.round(np.sqrt(merged_df[f'u_wind_{height_level}']**2 + merged_df[f'v_wind_{height_level}']**2),4)).all()\n",
    "#     assert (merged_df[f'wind_from_direction_{height_level}'] == np.round(np.rad2deg(np.arctan2(merged_df[f'v_wind_{height_level}'], merged_df[f'u_wind_{height_level}'])) + 180, 4)).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e96c131",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea19a3ba-716d-4b26-bc22-ac99e04cf382",
   "metadata": {},
   "source": [
    "Split train, test and validate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4205d3bf-b421-4298-8a5c-35126e904259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target has dims: 5\n",
      "dropping smallest bin: radar_fraction_in_band_instant_0.0\n",
      "getting profile columns\n",
      "{'nprof_features': 5, 'nheights': 33, 'nsinglvl_features': 0, 'nbands': 5}\n"
     ]
    }
   ],
   "source": [
    "test_fraction=0.2\n",
    "df_train, df_test = prd_pipeline.random_time_space_sample(merged_df, test_fraction=test_fraction, random_state=np.random.RandomState(), sampling_columns = ['time', 'latitude', 'longitude'])\n",
    "data_splits, data_dims_dict = prd_pipeline.preprocess_data(df_train, feature_dict, test_fraction=test_fraction/(1-test_fraction))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7b3a69c-a72d-4843-9715-b9a8fa51de2d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Plot pie charts of average fractions in bands"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cba87f9-cece-450b-9e5a-c15ff3dd236e",
   "metadata": {},
   "source": [
    "Make a copy of the training dataset and add a column which contains the label for the intensity band with the highest fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a56fe2-f07a-415f-a81b-ca0786d4482b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_copy = data_splits['y_train'].copy().reset_index(drop=True)\n",
    "y_train_copy['max_bin'] = y_train_copy.idxmax(axis=1)\n",
    "y_train_copy[y_train_copy['max_bin']==feature_dict['target'][-1]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4844f95-fd60-489b-ace3-c1484a17a8b9",
   "metadata": {},
   "source": [
    "Plot a pie chart of counts of the different intensity bands having highest fraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9d86fa-9254-4a62-a766-daabb1557e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_df = pd.DataFrame({'Counts': y_train_copy['max_bin'].value_counts()})\n",
    "avg_df.plot.pie(subplots=True)\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5,-0.1))\n",
    "plt.title('Intensity band with highest fraction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1955ffd-96a7-4ee3-b73d-b9479bdf994e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def pie_chart_mean_fractions_in_bands(df, title):\n",
    "    \"\"\"Calculates the average values of a pandas series provided and produces a pie chart\"\"\"\n",
    "    avg_df = pd.DataFrame({'Average': df.mean()})\n",
    "    avg_df.plot.pie(subplots=True)\n",
    "    plt.legend(loc='upper center', bbox_to_anchor=(0.5,-0.1))\n",
    "    plt.title(title)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d516a350-1624-4635-9bdd-76e4d04ca88c",
   "metadata": {},
   "source": [
    "Produce pie chart for the average fraction in each intensity band for the train, test and validate datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75722616-ce91-41e1-ac93-b599c3b4eb49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pie_chart_mean_fractions_in_bands(data_splits['y_train'], title='Average fraction in each intensity band - train dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6471dd74-0396-4bba-af65-c909b3404c51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pie_chart_mean_fractions_in_bands(data_splits['y_val'], title='Average fraction in each intensity band - validate dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37eda146-3692-4cdb-a7c7-c47a7b0e7684",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pie_chart_mean_fractions_in_bands(df_test[target_parameter], title='Average fraction in each intensity band - test dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418dd9c2-531c-4fcb-8970-ed9321101e1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits['y_train'].boxplot(rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e0aae5-0436-479b-b193-48b964f352a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits['nwp_val'].boxplot(rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7794be12-c573-45ff-8485-2843acab705e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_splits['y_val'].boxplot(rot=90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fe240f7-75a6-454c-8e72-1a1563cac76b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test[target_parameter].boxplot(rot=90)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2618217f-13e4-4b08-883d-4732d416f9a9",
   "metadata": {},
   "source": [
    "For each intensity band, select a subset which contains datapoint where the highest fraction falls into that intensity band, then produce the pie chart showing this average fraction in each intensity band. This allows us to see whether on average when a band has highest fraction whether it is marginally highest or is much higher than fractions of other bands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2fffb2-cfa7-41e6-a7dc-33fc2984425f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# y_train_copy = y_train_copy.reset_index(drop=True)\n",
    "# for col in y_train_copy.columns[:-1]:\n",
    "#     subset = y_train_copy[y_train_copy['max_bin']==col]\n",
    "#     pie_chart_mean_fractions_in_bands(subset, title=f'Average fraction in intensity band \\n highest frequency band {col} (nsamples = {len(subset)})')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55f5145c-9451-47e6-bb88-3592b0a236c2",
   "metadata": {},
   "source": [
    "### Class imbalance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18a01e5b-f3e8-4103-be81-448ef6a771fc",
   "metadata": {},
   "source": [
    "Calculate weights to input when fitting model, which is used for weighting the loss function in the model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44d0a26-83bd-4105-9f7e-9938746a0bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_copy['max_bin'] = y_train_copy.idxmax(axis=1)\n",
    "y_train_copy['max_bin'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a388c0b-1d84-4dcc-82b9-b38208c2773c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # weights = 1 / (tmp['max_bin'].value_counts() / tmp.shape[0]) / 4\n",
    "# weights = 1 / data_splits['y_train'].mean() / 100\n",
    "# weights = weights.reset_index(drop=True).to_dict()\n",
    "# weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ff6098-fdb8-4f75-ab1d-722255fadc23",
   "metadata": {},
   "source": [
    "Resample data to create more uniform distribution within the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6097d135-5615-4c40-9215-a426f7134592",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nsamples = len(y_train)//len(y_train.columns)\n",
    "# print('n samples =', nsamples)\n",
    "\n",
    "# y_train = pd.DataFrame()\n",
    "\n",
    "# y_train = y_train.reset_index(drop=True)\n",
    "\n",
    "# for col in y_train.columns[0:-1]:\n",
    "#     print(col)\n",
    "#     ids = y_train[y_train['max_bin']==col].index\n",
    "#     print(ids.shape)\n",
    "#     if len(ids)>0:\n",
    "#         choices = np.random.choice(ids, nsamples)\n",
    "#         y_train = pd.concat([y_train, y_train.loc[choices]])\n",
    "#         try: \n",
    "#             X_train = np.concatenate([X_train, data_splits['X_train'][choices]])\n",
    "#         except NameError:\n",
    "#             X_train = data_splits['X_train'][choices]\n",
    "\n",
    "# cols = data_splits['y_train'].columns\n",
    "# plt.plot(data_splits['y_train'].sum(axis=0), label='original data')\n",
    "# plt.plot(y_train[cols].sum(axis=0), label='resampled data')\n",
    "# plt.legend()\n",
    "# plt.show()\n",
    "\n",
    "# y_train = y_train.drop(columns=['max_bin'])\n",
    "\n",
    "# data_splits['X_train'] = X_train\n",
    "# data_splits['y_train'] = y_train\n",
    "# data_dims_dict['nbands'] = data_splits['y_train'].shapey_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d57977-45a5-4592-8cfe-c0f7ce911ff6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Run experiment\n",
    "\n",
    "Here we actually run the training and evaluation. All parameters and the output model will be saved through ML Flow, and we can track training stats through tensorboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2040403e-7a51-4943-9b08-b8e236f56fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_name='prd_fraction_models_mlflow'\n",
    "exp1 = mlflow.create_experiment(exp_name)\n",
    "exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44193041-19c7-4ee0-a2e8-981f8de4034f",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp1 = mlflow.get_experiment(exp1)\n",
    "exp1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4fc4fc3-9730-4822-93a2-9304476d84bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameter_dict = {\n",
    "    'epochs': 10, \n",
    "    'learning_rate': 0.001, \n",
    "    'batch_size': 64, \n",
    "    # 'class_weights': weights, \n",
    "    'loss': tf.keras.losses.KLDivergence()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acad9952-087e-479b-bd96-5e9ddc3b55fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with mlflow.start_run(experiment_id=exp1.experiment_id) as current_run:\n",
    "    mlflow.log_param('features', feature_dict['profile'] + feature_dict['single_level'])    \n",
    "    model = prd_pipeline.build_model(**data_dims_dict)\n",
    "    model.summary()\n",
    "    model, history = prd_pipeline.train_model(model, data_splits, hyperparameter_dict, log_dir='./logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e377663d-f26b-4cee-9436-d5966593ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(10),history.history['val_loss'])\n",
    "plt.plot(range(10), history.history['loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6431fc7a-41e0-4bab-8f6d-facde6aa2303",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(10), history.history['val_accuracy'])\n",
    "plt.plot(range(10), history.history['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12b84fe6-a432-499f-9949-f255f0198b5d",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Feature importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1672254-b061-446b-9997-99ad7220d7c6",
   "metadata": {},
   "source": [
    "Here we calculate the Breiman permutation importance for each of the model input features. This allows us to assess how much information each input feature is contributing to the resulting predictions from the ML model. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21fe783-a21d-46c2-bb26-04a4b3280984",
   "metadata": {},
   "source": [
    " - At each step, only one predictor is permuted (randomized)\n",
    " - The amount by which the loss function increases when 洧논 is randomized, is considered the importance of 洧논\n",
    " - If the loss function increases slightly when 洧논 is permuted, 洧논 is somewhat important\n",
    " - If the loss function explodes when 洧논 is permuted, 洧논 is very important\n",
    " - If the loss function remains the same or decreases when 洧논 is permuted, 洧논 is not important"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770d8d50-7f71-491f-b86d-f8ebf405e797",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = feature_dict['profile'] + feature_dict['single_level']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c87456-5e1b-4f73-99c5-31ede240ef2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline_metric = history.history['val_loss'][-1]\n",
    "npermutations=10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2651d0-4f49-4524-b31f-3e2ce2802422",
   "metadata": {},
   "outputs": [],
   "source": [
    "permutation_importance = prd_pipeline.calculate_permutation_feature_importance(model, data_splits, feature_dict, baseline_metric, npermutations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815ffcf4-8234-4981-8cf3-aac3aefd4c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_importance = {}\n",
    "for k,v in permutation_importance.items():\n",
    "    avg_importance[k] = np.mean(v)\n",
    "print(avg_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74c4ec33-edf4-4c34-9b6a-da301302de27",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(permutation_importance)\n",
    "df = df.reindex(columns=[k for k, v in sorted(avg_importance.items(), key=lambda item: item[1])])\n",
    "df.boxplot(showmeans=True, vert=False)\n",
    "plt.ylabel('Feature')\n",
    "plt.xlabel('Change in loss function by permuting feature')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3173531e-1224-45d1-a00a-cdf9f4d9e49d",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ba9b2b-7809-4f00-adac-f3db457682f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(data_splits['X_val'])\n",
    "\n",
    "pred_column_names = [intensity_band_template.format(source='ml', band_centre=threshold) for threshold in bands.keys()]\n",
    "y_pred_df = pd.DataFrame(y_pred, columns=pred_column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "394f73af-7fc1-4a56-8e6b-028d68283d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_df = pd.concat([\n",
    "    data_splits['meta_val'].reset_index(drop=True), \n",
    "    data_splits['nwp_val'].reset_index(drop=True), \n",
    "    data_splits['y_val'].reset_index(drop=True), \n",
    "    y_pred_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c55de0dc-07dc-4dd5-92c9-21438bb815f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = evaluation_df[evaluation_df.realization==0]\n",
    "for i in np.arange(1):\n",
    "    df.iloc[i][feature_dict['target']].plot(label='Radar')\n",
    "    df.iloc[i][feature_dict['nwp']].plot(label='NWP')\n",
    "    df.iloc[i][pred_column_names].plot(label='ML (control member)')\n",
    "    plt.ylabel('Fraction')\n",
    "    plt.xticks(np.arange(5), intensity_bands,rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26d82d2c-5426-4875-94f9-654e68034b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_df = evaluation_df.groupby(['time', 'latitude', 'longitude'])\n",
    "grouped_df_mean = grouped_df.agg('mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6010ca-d3e0-4a5d-977b-ea0ce5785c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in np.arange(1):\n",
    "    grouped_df_mean.iloc[i][feature_dict['target']].plot(label='Radar')\n",
    "    grouped_df_mean.iloc[i][feature_dict['nwp']].plot(label='NWP')\n",
    "    grouped_df_mean.iloc[i][pred_column_names].plot(label='ML (mean)')\n",
    "    plt.ylabel('Fraction')\n",
    "    plt.xticks(np.arange(5), intensity_bands,rotation=45, ha='right')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e53779f-c24c-44af-a353-effa05170341",
   "metadata": {},
   "outputs": [],
   "source": [
    "intensity_bands = ['0mm-0.01mm', '0.01mm-0.5mm', '0.5mm-4mm', '4mm-10mm', '>10mm']\n",
    "\n",
    "group_keys = list(grouped_df.groups.keys())\n",
    "for i in np.arange(1):\n",
    "    evaluation_df.iloc[grouped_df.groups[group_keys[i]]][pred_column_names].T.plot(lw=0.5, color='grey', label='_nolegend_')\n",
    "    \n",
    "    grouped_df_mean.iloc[i][feature_dict['target']].plot(label='Radar')\n",
    "    grouped_df_mean.iloc[i][feature_dict['nwp']].plot(label='NWP')\n",
    "    grouped_df_mean.iloc[i][pred_column_names].plot(label='ML (mean)', ls='--')\n",
    "    \n",
    "    plt.ylabel('Fraction')\n",
    "    plt.xticks(np.arange(5), intensity_bands, rotation=45, ha='right')\n",
    "    plt.legend(loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    plt.title(f'{group_keys[i][0]}\\n{group_keys[i][1:]}')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc55dc6-7949-41af-a90f-e510fd7303bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "intensity_bands = ['0mm-0.01mm', '0.01mm-0.5mm', '0.5mm-4mm', '4mm-10mm', '>10mm']\n",
    "\n",
    "group_keys = list(grouped_df.groups.keys())\n",
    "for i in np.arange(1):\n",
    "    x = np.arange(data_dims_dict['nbands'])  # the label locations\n",
    "    width = 0.25  # the width of the bars\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,5))\n",
    "    rects1 = ax.bar(x - width, grouped_df_mean.iloc[i][pred_column_names], width, label='ML predicted fractions (mean)')\n",
    "    rects2 = ax.bar(x + width, grouped_df_mean.iloc[i][feature_dict['target']], width, label='Radar fractions')\n",
    "    rects3 = ax.bar(x, grouped_df_mean.iloc[i][feature_dict['nwp']], width, label='NWP probabilities')\n",
    "\n",
    "    # Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "    ax.set_ylabel('Fraction in precip intensity band')\n",
    "    ax.set_xlabel('Precip intensity band')\n",
    "    ax.set_title('Instantenous precipitiation fractions in intensity bands')\n",
    "\n",
    "    plt.xticks(np.arange(5), intensity_bands)\n",
    "    ax.legend()\n",
    "\n",
    "    fig.tight_layout()\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "229b0eea-a72f-482f-acb6-f69ab3eb912d",
   "metadata": {},
   "source": [
    "Fractional skill score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af178bc4-9fd4-49d9-a151-b0aa5fe24b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_fss(obs, fx):\n",
    "    \"\"\" \n",
    "    The inputs to this function are the cumulative probability/fraction of exceeding a given precipitation threshold\n",
    "    \"\"\"\n",
    "    FBS = ((fx - obs)**2).sum()\n",
    "    FBS_ref = (fx**2).sum() + (obs**2).sum()\n",
    "    FSS = 1 - (FBS/FBS_ref)\n",
    "    return FSS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f9adce-62bb-4d03-b0fe-c15e45a73054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate FSS - each ensemble member produced ML prediction and treated as deterministic \n",
    "for i, col in enumerate(target_parameter):\n",
    "    y_test = 1 - data_splits['y_val'][target_parameter[:i+1]].sum(axis=1)\n",
    "    y_test[y_test<0] = 0\n",
    "    nwp_test = 1 - data_splits['nwp_val'][nwp_comparison[i+5]].sum(axis=1)\n",
    "    nwp_test[nwp_test<0]=0\n",
    "    y_cumulative_pred = 1 - y_pred[:,:i+1].sum(axis=1)\n",
    "    y_cumulative_pred[y_cumulative_pred<0]=0\n",
    "    print(f'ML FSS (intensity band {intensity_bands[i]}) {calculate_fss(y_test, y_cumulative_pred):.4f}')\n",
    "    print(f'NWP FSS (intensity band {intensity_bands[i]}) {calculate_fss(y_test, nwp_test):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86e38c0-3033-4bdc-b2e5-7109314befce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate FSS for mean of ML prediction from set of ens members\n",
    "grouped = evaluation_df.groupby(['time', 'latitude', 'longitude']).agg('mean')\n",
    "for i, col in enumerate(target_parameter):\n",
    "    y_test = 1 - grouped[target_parameter[:i+1]].sum(axis=1)\n",
    "    y_test[y_test<0] = 0\n",
    "    nwp_test = 1 - grouped[nwp_comparison[i+5]].sum(axis=1)\n",
    "    nwp_test[nwp_test<0]=0\n",
    "    y_cumulative_pred = 1 - grouped[pred_column_names[:i+1]].sum(axis=1)\n",
    "    y_cumulative_pred[y_cumulative_pred<0]=0\n",
    "    print(f'ML FSS (intensity band {intensity_bands[i]}) {calculate_fss(y_test, y_cumulative_pred):.4f}')\n",
    "    print(f'NWP FSS (intensity band {intensity_bands[i]}) {calculate_fss(y_test, nwp_test):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d080c9d-029a-4dd7-9da3-98690453f200",
   "metadata": {},
   "source": [
    "# Plot of FSS on map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ff3beb-0acb-4105-a82e-e4198e759ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fss_for_grid(df, model, feature_dict, data_dims_dict):\n",
    "    X_test_df, y_test_df, nwp_test_df = prd_pipeline.load_test_data(df, feature_dict, data_dims_dict)\n",
    "\n",
    "    ypred_test_df = model.predict(X_test_df)\n",
    "    \n",
    "    # calculate cumulative probabilities  - WHY DOES THIS NOT WORK??\n",
    "    y_pred_cdf = 1 - ypred_test_df.cumsum(axis=1)\n",
    "    y_pred_cdf[y_pred_cdf<0]=0  # Some cumulative fractions sum to just over 1 due to rounding error\n",
    "\n",
    "    y_test_cdf = 1 - y_test_df.cumsum(axis=1)\n",
    "    y_test_cdf[y_test_cdf<0]=0  # Some cumulative fractions sum to just over 1 due to rounding error\n",
    "\n",
    "    nwp_test_cdf = 1 - nwp_test_df.cumsum(axis=1)\n",
    "    nwp_test_cdf[nwp_test_cdf<0]=0  # Some cumulative fractions sum to just over 1 due to rounding error\n",
    "    \n",
    "    # calculative fractional skill score \n",
    "    ml_fss, nwp_fss = [], [] \n",
    "    for i, col in enumerate(feature_dict['target']):\n",
    "        # ml_fss.append(calculate_fss(y_test_cdf.iloc[:,i], y_pred_cdf[:,i]))\n",
    "        # nwp_fss.append(calculate_fss(y_test_cdf.iloc[:,i], nwp_test_cdf.iloc[:,i]))\n",
    "        \n",
    "        ml = y_pred_cdf[:,i]\n",
    "        nwp = nwp_test_cdf.iloc[:,i]\n",
    "        radar = y_test_cdf.iloc[:,i]\n",
    "\n",
    "#         radar = radar[ml > 0]\n",
    "#         nwp = nwp[ml > 0]\n",
    "#         ml = ml[ml > 0]\n",
    "\n",
    "#         radar = radar[nwp > 0]\n",
    "#         ml = ml[nwp > 0]\n",
    "#         nwp = nwp[nwp > 0]\n",
    "\n",
    "        ml_fss.append(calculate_fss(radar, ml))\n",
    "        nwp_fss.append(calculate_fss(radar, nwp))\n",
    "    \n",
    "    ml_fss_names = ['_'.join(['ml_fss'] + [name.split('_')[-1]]) for name in feature_dict['target']]\n",
    "    nwp_fss_names = ['_'.join(['nwp_fss'] + [name.split('_')[-1]]) for name in feature_dict['target']]\n",
    "    \n",
    "    return pd.concat([pd.Series(ml_fss, index=ml_fss_names), pd.Series(nwp_fss, index=nwp_fss_names)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d1ae0f9-310e-41a2-85c1-1afcfc6e51f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To calculate FSS of fraction predicted by ML model treating each ensemble members as deterministic\n",
    "# fss_grid = merged_df.groupby(['latitude', 'longitude']).apply(lambda x: fss_for_grid(x, model, feature_dict, data_dims_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c086559e-044b-40fd-824d-076ce158aac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To calculate FSS of mean fraction predicted by ML model for ensemble members from same model run\n",
    "# grid_grouped_df = merged_df.groupby(['time', 'latitude', 'longitude']).agg('mean').reset_index()\n",
    "# fss_grid = grid_grouped_df.groupby(['latitude', 'longitude']).apply(lambda x: fss_for_grid(x, model, feature_dict, data_dims_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab6dbe5-d3bc-4413-bc86-225ecc277467",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# To calculate FSS of mean fraction predicted by ML model for ensemble members from same model run\n",
    "fss_grid = merged_df[merged_df.realization==0].groupby(['latitude', 'longitude']).apply(lambda x: fss_for_grid(x, model, feature_dict, data_dims_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2480642f-8658-4b0f-8aa2-e4cc3732c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fss_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e3d84-70e6-4b29-96e9-4211ccfc1be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fss_grid.to_csv('fss_ml_control_pred.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89d570c9-1682-4fa8-a091-5dfd1a4c31d3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prd_model_dev_azml_001",
   "language": "python",
   "name": "prd_model_dev_azml_001"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
