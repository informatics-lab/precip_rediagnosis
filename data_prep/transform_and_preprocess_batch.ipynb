{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "exact-valentine",
   "metadata": {},
   "source": [
    "# Pre-processing the data - batch\n",
    "This notebook follows on from `transform_and_preprocess_spice.ipynb`, so look at that first for an explanation of processing. This notebook has the same processing in fewer commands and in a loop across forecast ref times. Along the way intermediate data is also output, including:\n",
    "* MOGREPS-G gridded data for UK, all variables in one file.\n",
    "* MOGREPS-G data for UK in tabular form\n",
    "* Radar data regridded onto MOGREPS-G grid and summed to 3hr accumualtions, one file\n",
    "* Radar data on MOGREPS-G grid and summed to 3hr accumualtions in tabular form\n",
    "* Final output: Merged MOGREPS-G and radar data in tabular\n",
    "\n",
    "Changing the initial parameter (such as time and location) should allow duplicated o f this notebook to work for other timeperiods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "willing-tenant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import datetime\n",
    "import functools\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "desperate-thousand",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "explicit-hamilton",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "devoted-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "import xarray\n",
    "import iris\n",
    "import iris.quickplot\n",
    "import iris.coord_categorisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "216c2d69-2655-44b3-80a4-c12d3e637800",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "documented-campus",
   "metadata": {},
   "source": [
    "# Set parameters for notebook\n",
    "Set the paths and lists of things to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c725213e-5ab1-45da-89f1-750b5dbbf334",
   "metadata": {},
   "outputs": [],
   "source": [
    "project_name = 'precip_rediagnosis'\n",
    "mogreps_g_name = 'mogreps-g'\n",
    "ilab_project_dir = pathlib.Path('/project/informatics_lab/')\n",
    "output_dir =  pathlib.Path('/scratch')/ os.environ['USER'] / project_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "union-agent",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data_dir = ilab_project_dir / project_name\n",
    "mogreps_g_data_dir = root_data_dir / mogreps_g_name\n",
    "radar_data_dir = root_data_dir / 'radar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aac0f0e8-2b5c-4b36-b8c6-246e3e887bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "date_fname_template = '{start.year:04d}{start.month:02d}{start.day:02d}T{start.hour:02d}{start.minute:02d}Z_{end.year:04d}{end.month:02d}{end.day:02d}T{end.hour:02d}{end.minute:02d}Z'\n",
    "fname_extension_grid = '.nc'\n",
    "fname_extension_tabular = '.csv'\n",
    "leadtime_template = '{lt:03d}H'\n",
    "mogreps_g_tab_fname_template = 'prd_mogreps_g_' + leadtime_template + '_' + date_fname_template + fname_extension_tabular\n",
    "mogreps_g_grid_fname_template = 'prd_mogreps_g_' + leadtime_template + '_' + date_fname_template + fname_extension_grid\n",
    "radar_tab_fname_template = 'prd_radar_' + date_fname_template + fname_extension_tabular\n",
    "radar_grid_fname_template = 'prd_radar_' + date_fname_template + fname_extension_grid\n",
    "output_fname_template = 'prd_merged_' + leadtime_template + '_' + date_fname_template + fname_extension_tabular"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "operational-fundamentals",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_single_level = [\n",
    "    \"cloud_amount_of_total_cloud\",\n",
    "    \"rainfall_accumulation-PT03H\",\n",
    "    \"snowfall_accumulation-PT03H\",\n",
    "    \"rainfall_rate\",\n",
    "    \"snowfall_rate\",\n",
    "    \"height_of_orography\",\n",
    "    \"pressure_at_mean_sea_level\",\n",
    "]\n",
    "\n",
    "variables_height_levels = [\n",
    "    \"cloud_amount_on_height_levels\",\n",
    "    \"pressure_on_height_levels\",\n",
    "    \"temperature_on_height_levels\",\n",
    "    \"relative_humidity_on_height_levels\",\n",
    "    \"wind_direction_on_height_levels\",\n",
    "    \"wind_speed_on_height_levels\",\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cooked-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_periods = 10\n",
    "start_ref_time = datetime.datetime(2020,2,14,12)\n",
    "forecast_ref_time_range = [start_ref_time + datetime.timedelta(hours=6)*i1 for i1 in range(num_periods)]\n",
    "leadtime_hours = 15\n",
    "realizations_list = list(range(35))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "passing-infection",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = 'mogreps-g'\n",
    "subset = 'lev1'\n",
    "forecast_ref_template = '{frt.year:04d}{frt.month:02d}{frt.day:02d}T{frt.hour:02d}00Z.nc.file'\n",
    "fname_template = '{vt.year:04d}{vt.month:02d}{vt.day:02d}T{vt.hour:02d}00Z-PT{lead_time:04d}H00M-{var_name}.nc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "neural-meter",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables_to_extract = variables_height_levels + variables_single_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "finite-leeds",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_lists_vars = {\n",
    "    var_name: [f1 for f1 in mogreps_g_data_dir.iterdir() if var_name in str(f1)]\n",
    "    for var_name in variables_to_extract\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "70e6e4ad-0b11-4dce-8e2f-be0d276b9095",
   "metadata": {},
   "outputs": [],
   "source": [
    "uk_bounds={'latitude':(50,58), 'longitude': (-6,2)}\n",
    "xarray_select_uk = {k1: slice(*v1) for k1,v1 in uk_bounds.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2cacb1-849e-496b-8848-f4cdacfd6cb4",
   "metadata": {},
   "source": [
    "## Load radar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dba573d6-215c-43f3-a4c5-1ee74bdba332",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_days = [datetime.datetime(2020,2,14) + datetime.timedelta(days=d1) for d1 in range(5)]\n",
    "radar_days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2245d7d-a1c8-48ff-9f87-f697f393dd0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_fname_template = 'composite_rainfall_{dt.year:04d}{dt.month:02d}{dt.day:02d}.nc'\n",
    "radar_cube = iris.cube.CubeList([iris.load_cube(str(radar_data_dir / radar_fname_template.format(dt=dt1))) for dt1 in radar_days] ).concatenate_cube()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c29d2d2-573e-40c8-a1f1-917f73ed9cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.coord_categorisation.add_hour(radar_cube, coord='time')\n",
    "iris.coord_categorisation.add_day_of_year(radar_cube, coord='time')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d97b6ba7-6f7d-4731-b98f-cabf1b5b0416",
   "metadata": {},
   "source": [
    "Load a sample variable from MOGREPS-G to use for regridding radar data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec2a8e2-1258-440b-ab55-59bd0031bd4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mogreps_g_example = iris.load_cube(\n",
    "    str(mogreps_g_data_dir / fname_template.format(\n",
    "        vt=forecast_ref_time_range[0] + datetime.timedelta(hours=leadtime_hours), \n",
    "        lead_time=leadtime_hours, \n",
    "        var_name=variables_single_level[0])),\n",
    "    iris.Constraint(latitude=lambda cell1: uk_bounds['latitude'][0] < cell1 < uk_bounds['latitude'][1], \n",
    "                                                     longitude=lambda cell1: uk_bounds['longitude'][0] < cell1 < uk_bounds['longitude'][1], realization=0)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bfbd13-aeaa-48ae-92ac-c20a90ad40fe",
   "metadata": {},
   "source": [
    "Aggregate the instantaneous rates to get an accumulation (this makes the assumption that the rates represent the accumulation for the 5 minute period)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d58dc4c4-9ca6-4a60-9b44-bb7365b56b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "coord_3hr = iris.coords.AuxCoord(radar_cube.coord('hour').points // 3,\n",
    "                                long_name='3hr',\n",
    "                                 units='hour',\n",
    "                                )\n",
    "radar_cube.add_aux_coord(coord_3hr, data_dims=0)\n",
    "radar_agg = radar_cube.aggregated_by(['3hr', 'day_of_year'],iris.analysis.SUM)\n",
    "radar_agg.add_aux_coord(iris.coords.AuxCoord([c1.bound[0] + datetime.timedelta(hours=3) for c1 in radar_agg.coord('time').cells()], long_name='model_accum_time', units='mm/h'), data_dims=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11e2391-cfec-403b-873f-bc48b6a0d870",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_mggrid = radar_agg.regrid(mogreps_g_example, iris.analysis.Linear())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da33c7bb-0117-4a68-941a-bb04f7a50d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_mggrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "454be1bd-c3d2-48db-9d91-be64d7ec29da",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_mggrid.remove_coord('model_accum_time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0100ee0a-f08f-4115-b098-35fb78ab71da",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_mggrid.remove_coord('3hr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be44302a-caae-4062-8941-643170e9860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cftime_to_datetime(input_cft):\n",
    "    return datetime.datetime(input_cft.year,\n",
    "                             input_cft.month,\n",
    "                             input_cft.day,\n",
    "                             input_cft.hour,\n",
    "                             input_cft.minute,\n",
    "                             input_cft.second,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "835780f8-a14a-4ac4-a099-fa2e3eef1c7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74569d1-360a-48aa-a5ab-700f3ef568e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.save(radar_mggrid, \n",
    "          str(output_dir / radar_grid_fname_template.format(start=min([cftime_to_datetime(cell1.point) for cell1 in radar_mggrid.coord('time').cells()]),\n",
    "                                                            end=max([cftime_to_datetime(cell1.point) for cell1 in radar_mggrid.coord('time').cells()])\n",
    "                                                           )))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b452a7-8e8a-4fb8-9487-7ff62d738de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_acc_regrid_df = xarray.DataArray.from_iris(radar_mggrid).to_dataframe().reset_index()\n",
    "radar_acc_regrid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382c19e3-a738-4a03-989f-4c42ef7ae0e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_acc_regrid_df = radar_acc_regrid_df.rename({'time': 'period_midpoint'}, axis='columns')\n",
    "radar_acc_regrid_df['time'] = radar_acc_regrid_df['period_midpoint'].apply(lambda dt1: datetime.datetime(dt1.year, dt1.month, dt1.day, dt1.hour, dt1.minute,dt1.second) + datetime.timedelta(hours=1,minutes=32,seconds=30))\n",
    "radar_acc_regrid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "773cca0c-13e2-4530-97ba-7d26a5595bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_acc_regrid_df.to_csv(output_dir / radar_tab_fname_template.format(start=radar_acc_regrid_df['time'].min(),\n",
    "                                                                        end=radar_acc_regrid_df['time'].min(),\n",
    "                                                                       ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binary-worker",
   "metadata": {},
   "source": [
    "## Create a dataset from MOGREPS-G data\n",
    "Information on Met Office Ensmble forecasts - https://www.metoffice.gov.uk/research/weather/ensemble-forecasting#\n",
    "Paper - https://www.metoffice.gov.uk/research/weather/ensemble-forecasting "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5086ee-9112-47dc-8d1e-2053c9e5af29",
   "metadata": {},
   "source": [
    "### Get the mapping of variable names \n",
    "Load some files and get the actual variable names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ruled-effort",
   "metadata": {},
   "outputs": [],
   "source": [
    "fcst_ref_time = forecast_ref_time_range[0]\n",
    "real1 = realizations_list[10]\n",
    "validity_time = fcst_ref_time + datetime.timedelta(hours=leadtime_hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "russian-letter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 523 ms, sys: 74.4 ms, total: 597 ms\n",
      "Wall time: 1.7 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'cloud_amount_of_total_cloud': 'cloud_area_fraction',\n",
       " 'rainfall_accumulation-PT03H': 'thickness_of_rainfall_amount',\n",
       " 'snowfall_accumulation-PT03H': 'lwe_thickness_of_snowfall_amount',\n",
       " 'rainfall_rate': 'rainfall_rate',\n",
       " 'snowfall_rate': 'lwe_snowfall_rate',\n",
       " 'height_of_orography': 'surface_altitude',\n",
       " 'pressure_at_mean_sea_level': 'air_pressure_at_sea_level',\n",
       " 'cloud_amount_on_height_levels': 'cloud_volume_fraction_in_atmosphere_layer',\n",
       " 'pressure_on_height_levels': 'air_pressure',\n",
       " 'temperature_on_height_levels': 'air_temperature',\n",
       " 'relative_humidity_on_height_levels': 'relative_humidity',\n",
       " 'wind_direction_on_height_levels': 'wind_from_direction',\n",
       " 'wind_speed_on_height_levels': 'wind_speed'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# load a cube for each variable in iris to get the actual variable name, and populate dictionary mapping from the var name in the file name to the variable as loaded into iris/xarray\n",
    "file_to_var_mapping = {\n",
    "    var_file_name: iris.load_cube(str(mogreps_g_data_dir / fname_template.format(vt=validity_time,\n",
    "                                                                                 lead_time=leadtime_hours,\n",
    "                                                                                 var_name=var_file_name))).name()\n",
    "    for var_file_name in variables_single_level + variables_height_levels}\n",
    "file_to_var_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4cf31e36-7d2b-4de9-9671-bfa81b4ac24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "heights = iris.load_cube(str(mogreps_g_data_dir / fname_template.format(vt=validity_time,\n",
    "                                                                                 lead_time=leadtime_hours,\n",
    "                                                                                 var_name=variables_height_levels[0]))).coord('height').points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "db38977d-efa7-4098-b189-0d2bba3db717",
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_coords = ['latitude', 'longitude', 'time', 'realization']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dbc762f8-8aa7-4e90-bbd4-1b52d664aecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "single_level_var_mappings = {v1: file_to_var_mapping[v1] for v1 in variables_single_level}\n",
    "height_level_var_mappings = {v1: file_to_var_mapping[v1] for v1 in variables_height_levels}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "demanding-checkout",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ds(ds_path, selected_bounds):\n",
    "    try:\n",
    "        subset1 = dict(selected_bounds)\n",
    "        subset1['bnds'] = 0\n",
    "        single_level_ds = xarray.load_dataset(ds_path).sel(**subset1)\n",
    "    except KeyError as e1:\n",
    "        single_level_ds = None\n",
    "    return single_level_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3350c30d-7af8-42c5-a183-ba48f5e44f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-14 12:00:00\n",
      "cloud_volume_fraction_in_atmosphere_layer\n",
      "air_pressure\n",
      "air_temperature\n",
      "relative_humidity\n",
      "wind_from_direction\n",
      "wind_speed\n",
      "2020-02-14 18:00:00\n",
      "cloud_volume_fraction_in_atmosphere_layer\n",
      "air_pressure\n",
      "air_temperature\n",
      "relative_humidity\n",
      "wind_from_direction\n",
      "wind_speed\n",
      "2020-02-15 00:00:00\n",
      "cloud_volume_fraction_in_atmosphere_layer\n",
      "air_pressure\n",
      "air_temperature\n",
      "relative_humidity\n",
      "wind_from_direction\n",
      "wind_speed\n",
      "2020-02-15 06:00:00\n",
      "cloud_volume_fraction_in_atmosphere_layer\n",
      "air_pressure\n",
      "air_temperature\n",
      "relative_humidity\n",
      "wind_from_direction\n",
      "wind_speed\n",
      "2020-02-15 12:00:00\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ts_data_list = []\n",
    "# gridded_data_list = []\n",
    "for fcst_ref_time in forecast_ref_time_range:\n",
    "    print(fcst_ref_time)\n",
    "    validity_time = fcst_ref_time + datetime.timedelta(hours=leadtime_hours)\n",
    "    single_level_ds = xarray.merge([load_ds(ds_path= mogreps_g_data_dir / fname_template.format(vt=validity_time,\n",
    "                                                                                                lead_time=leadtime_hours,\n",
    "                                                                                                var_name=var1),\n",
    "                                            selected_bounds=xarray_select_uk,\n",
    "                                           )\n",
    "                                    for var1 in variables_single_level]\n",
    "                                  )\n",
    "    single_level_df = single_level_ds.to_dataframe().reset_index()\n",
    "\n",
    "    height_levels_ds = xarray.merge([load_ds(ds_path=mogreps_g_data_dir / fname_template.format(vt=validity_time,\n",
    "                                                                                                lead_time=leadtime_hours,\n",
    "                                                                                                var_name=var1),\n",
    "                                             selected_bounds=xarray_select_uk,\n",
    "                                            )\n",
    "                                     for var1 in variables_height_levels])\n",
    "    hl_df_multirow = height_levels_ds.to_dataframe().reset_index()\n",
    "    \n",
    "    var_df_merged = []\n",
    "    # heights_vars_marged = height_levels_df[height_levels_df.height==heights[0]][ merge_coords]\n",
    "    for var1 in height_level_var_mappings.values():\n",
    "        print(var1)\n",
    "        # for h1 in heights:\n",
    "        #     heights_vars_marged[f'{var1}_{h1:.1f}'] = list(height_levels_df[height_levels_df.height==h1][var1])\n",
    "        var_at_heights = [hl_df_multirow[hl_df_multirow.height==h1][merge_coords + [var1]].rename({var1: f'{var1}_{h1:.1f}'}, axis='columns') for h1 in heights]\n",
    "        var_df_merged += [functools.reduce(lambda x,y: x.merge(y, on=merge_coords), var_at_heights)]\n",
    "    height_levels_df = functools.reduce(lambda x,y: x.merge(y, on=merge_coords), var_df_merged)    \n",
    "    \n",
    "    mogreps_g_single_ts_uk_df = single_level_df.merge(height_levels_df, on=merge_coords)\n",
    "    mogreps_g_single_ts_uk_df\n",
    "    \n",
    "    mogreps_g_single_ts_uk_df = single_level_df.merge(height_levels_df, on=merge_coords)\n",
    "    ts_data_list += [mogreps_g_single_ts_uk_df]\n",
    "    ts_mogg_ds1 = xarray.merge([height_levels_ds, single_level_ds])\n",
    "    ts_mogg_ds1.to_netcdf(output_dir / (\n",
    "        'prd_mg_ts_'+ f'{validity_time.year:04d}{validity_time.month:02d}{validity_time.day:02d}{validity_time.hour:02d}{validity_time.minute:02d}' \n",
    "        + fname_extension_grid)\n",
    "    )\n",
    "    # gridded_data_list += [xarray.merge([height_levels_ds, single_level_ds])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7bff449-433b-4722-b38d-ea9c30922df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prd_mogreps_grid_ds = xarray.concat(gridded_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "263f34b3-1ffa-4514-83ad-3f288fce7c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prd_mogreps_grid_ds.to_netcdf(output_dir / mogreps_g_grid_fname_template.format(lt=leadtime_hours,\n",
    "#                                                                                 start=prd_column_dataset['time'].min(),\n",
    "#                                                                                 end=prd_column_dataset['time'].max(),\n",
    "#                                                                                ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "median-macintosh",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "prd_column_dataset = pandas.concat(ts_data_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71c73ca-4008-41a8-ad87-ad5b24695450",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_column_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f3b4a8e-705c-4f19-a0fd-48c4ba0a5713",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_column_dataset.to_csv(output_dir / mogreps_g_tab_fname_template.format(lt=leadtime_hours,\n",
    "                                                                           start=prd_column_dataset['time'].min(),\n",
    "                                                                           end=prd_column_dataset['time'].max(),\n",
    "                                                                          ))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea23353-2e86-4634-aca3-00d7e7358411",
   "metadata": {},
   "source": [
    "## Merging radar and model data\n",
    "We have now created a table with radar data and a table with MOGREPS-G model data. We  now wantto merge them into a single. The steps are as follows\n",
    "* trim the time periods so the data covers matching times\n",
    "* do a merge on latitude, longitude and time. \n",
    "  * We don't merge on realization as done for merging the different model fields, as radar is not ensemble data. Instead, the type of merge chosen will insert the radar composite rainfall field for each row with with the correct time and place, so will appear multiple times for each realization present at that timestamp\n",
    "* Output resulting table to disk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d9920a-c8e8-470a-a189-048189e6d178",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_column_dataset.time.min(), prd_column_dataset.time.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8188d1cc-9cf0-48e1-9b7b-10bc7657298d",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_acc_regrid_df = radar_acc_regrid_df[(radar_acc_regrid_df['time'] >= prd_column_dataset.time.min()) & (radar_acc_regrid_df['time'] <= prd_column_dataset.time.max())]\n",
    "radar_acc_regrid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bec0f7-7e79-4599-823a-8d87664f8745",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_merged_mogreps_radar = prd_column_dataset.merge(radar_acc_regrid_df, on=['latitude', 'longitude','time'], how='inner')\n",
    "prd_merged_mogreps_radar"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411ef22f-3029-4c35-a7da-c85089765d29",
   "metadata": {},
   "source": [
    "Looking at the results of the merge, we see that we have different values for model output for different realisations at the same time and location, but all of those datapoints will have the same value for radar rainfall accumulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb8f60cd-5325-400c-9756-6066cbe1f62b",
   "metadata": {},
   "outputs": [],
   "source": [
    "prd_merged_mogreps_radar[(prd_merged_mogreps_radar['time'] == '2020-02-16T015:00') &\n",
    "                         (prd_merged_mogreps_radar['latitude'] == 50.15625) &\n",
    "                         (prd_merged_mogreps_radar['longitude'] == -5.765625) \n",
    "                        ][['latitude','longitude','realization', 'time','air_temperature_5.0','rainfall_rate_composite']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df573d4-2f32-4477-8d97-2859975d5ce5",
   "metadata": {},
   "source": [
    "### Output to Tabular data format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5a3b0f2-1baf-457f-9760-ca66b84b3402",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_dt = prd_merged_mogreps_radar['time'].min()\n",
    "end_dt = prd_merged_mogreps_radar['time'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "modern-software",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_fname = output_fname_template.format(lt=leadtime_hours,\n",
    "                                            start=start_dt,\n",
    "                                            end=end_dt,\n",
    "                                           )\n",
    "output_path = output_dir / output_fname\n",
    "print(output_path)\n",
    "prd_merged_mogreps_radar.to_csv(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mexican-implementation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO:add parquet to conda environment and save as parquet format\n",
    "#prd_merged_mogreps_radar.to_parquet(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be3c506e-65e4-4318-8382-b34a3ecc49d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prd_data_prep (Conda)",
   "language": "python",
   "name": "prd_data_prep"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
